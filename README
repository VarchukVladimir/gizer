1. Add directory containing mongo_schema module to python path. 
If module resided in git directory: export PYTHONPATH=~/git/

2.Specify TEST_PSQLCONN env variable before running tests, for example:
  export TEST_PSQLCONN="dbname=zvm user=zvm"

3. Test it
./run_cov_tests.sh or py.test

4. Tools.
4.1. mongo_reader.py
     It's creates relational model of data for specific collection and then saves all collection's data into csv files.
4.2. psql_copy.py
     Export scv files previously created by mongo_reader.py into postgres tables.
4.3. copy_object_from_psql_to_psql.py
     Copy tables rows related to specific mongo record data to the same or to another psql DB. Copying into same DB is much faster than copying to different DB instance as using different approaches.

5. Examples
python mongo_schema/get_mongo_schema_as_json.py --host localhost:27017  -cn test.get_sql_query_tests > get_sql_query_tests.js
python mongo_reader.py --host localhost:27017  -cn test.get_sql_query_tests -ifs get_sql_query_tests.js
more examples:
time python mongo_reader.py --host $MONGO_URI_SSL -cn quote_management.quotes -user $MONGO_USER -passw $MONGO_PASS -ifs ~/schema/pregenerated/quotes_schema_verified.json -psql-schema-name quote_mgmt_ods -ssl --ddl-statements-file quotes.sql --csv-path tmp -psql-table-name-prefix 2016_04_11_ -stats-file quotes.stat
time python psql_copy.py -cn migration_jobs -ifs ~/schema/pregenerated/migration_jobs.json --psql-table-prefix 2016_04_11_ --psql-table-name migration_job_arguments --input-csv-dir tmp/migration_job_arguments/
time python copy_object_from_psql_to_psql.py -cn quotes -ifs ~/schema/pregenerated/quotes_schema_verified.json --src-psql-schema-name quote_mgmt_ods --rec-id 504983

